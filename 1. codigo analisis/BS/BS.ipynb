{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17264690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.pkl' with the actual path to your .pkl file\n",
    "with open('../2. data/llegadas.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09070d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruebas Waiting list\n",
    "wl = WL([1,2,3], [5,6,7,8])\n",
    "\n",
    "for paciente in pacientes_prueba_1:\n",
    "    if paciente.grd in wl.sub_listas[paciente.requerimiento_inicial]:\n",
    "        wl.agregar_paciente(paciente)\n",
    "        # print(f\"Paciente {paciente.id} agregado a la sublista {paciente.requerimiento_inicial} - GRD {paciente.grd}\")\n",
    "\n",
    "print(wl)\n",
    "\n",
    "wl.actualizar_tiempo()\n",
    "\n",
    "print(wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ca168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se instancian a todos los pacientes a partir de los datos de incertidumbre\n",
    "pacientes = {}\n",
    "lista_pacientes = []\n",
    "for hospital in range(0,4): # 0 son llegadas a WL\n",
    "    pacientes[hospital] = {}\n",
    "    for requerimiento in range(1,4):\n",
    "        pacientes[hospital][requerimiento] = {}\n",
    "        for grd in range(1,9):\n",
    "            pacientes[hospital][requerimiento][grd] = []\n",
    "            cantidad_pacientes = len(incertidumbre[hospital][requerimiento][grd])\n",
    "            if cantidad_pacientes != 0:\n",
    "                for i in range(cantidad_pacientes):\n",
    "                    paciente = Paciente(hospital, requerimiento, grd, incertidumbre[hospital][requerimiento][grd][i]) # i es el index de la lista\n",
    "                    pacientes[hospital][requerimiento][grd].append(paciente)\n",
    "                    lista_pacientes.append(paciente)\n",
    "            else:\n",
    "                pacientes[hospital][requerimiento][grd] = []\n",
    "\n",
    "# Se generan tantas listas como pacientes haya\n",
    "def agrupar_pacientes_por_llegada(pacientes):\n",
    "    pacientes_separados_por_llegada = {}\n",
    "    for paciente in pacientes:\n",
    "        dia = paciente.ti_inicial\n",
    "        if dia not in pacientes_separados_por_llegada:\n",
    "            pacientes_separados_por_llegada[dia] = []\n",
    "        pacientes_separados_por_llegada[dia].append(paciente)\n",
    "    return pacientes_separados_por_llegada\n",
    "\n",
    "pacientes_separados_por_llegada = agrupar_pacientes_por_llegada(lista_pacientes)\n",
    "pacientes_prueba_1 = pacientes_separados_por_llegada.get(2).copy()\n",
    "pacientes_prueba_2 = pacientes_separados_por_llegada.get(3).copy()\n",
    "\n",
    "wl = WL([1,2,3], [1,2,3,4,5,6,7,8])\n",
    "ps = PS([1, 2, 3], [1, 2, 3, 4, 5, 6, 7, 8])\n",
    "end = End([1, 2, 3], [1, 2, 3, 4, 5, 6, 7, 8])\n",
    "h_1 = Hospital(1)\n",
    "h_2 = Hospital(2)\n",
    "h_1.ocupacion()\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(1, 6):\n",
    "        h_1.agregar_paciente(pacientes_prueba_1.pop(), j)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(1, 6):\n",
    "        h_2.agregar_paciente(pacientes_prueba_2.pop(), j)\n",
    "\n",
    "pacientes_ed_1 = h_1.ED.pacientes.copy()\n",
    "pacientes_ed_2 = h_2.ED.pacientes.copy()\n",
    "\n",
    "h_1.actualizar_tiempo()\n",
    "for paciente in pacientes_ed_1:\n",
    "    h_1.sacar_paciente(paciente, p.dict_unidades[\"ED\"])\n",
    "    ps.agregar_paciente(paciente)\n",
    "\n",
    "h_2.actualizar_tiempo()\n",
    "for paciente in pacientes_ed_2:\n",
    "    h_2.sacar_paciente(paciente, p.dict_unidades[\"ED\"])\n",
    "    ps.agregar_paciente(paciente)\n",
    "\n",
    "# print(ps)\n",
    "\n",
    "for requerimiento in ps.sub_listas:\n",
    "    for grd in ps.sub_listas[requerimiento]:\n",
    "        if len(ps.sub_listas[requerimiento][grd]) > 0:\n",
    "            for paciente in ps.sub_listas[requerimiento][grd]:\n",
    "                for log in paciente.log_eventos:\n",
    "                    print(log)\n",
    "                print(\"----------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flujo para hacer que pacientes pasen por todas las unidades que necesitan\n",
    "\n",
    "\n",
    "def imprimir_log(log_eventos: list, ultimo = False):\n",
    "    if not ultimo:\n",
    "        for evento in log_eventos:\n",
    "            print(evento)\n",
    "    else:\n",
    "        print(log_eventos[-1])\n",
    "\n",
    "paciente_ed_1 = None\n",
    "paciente_ed_2 = None\n",
    "paciente_ed_3 = None\n",
    "paciente_wl = None\n",
    "for ciclo in range(1, 4):\n",
    "    for paciente in pacientes_separados_por_llegada[ciclo]:\n",
    "        if paciente.unidad_actual == p.dict_unidades[\"ED\"] and paciente.hospital_actual == 1:\n",
    "            paciente_ed_1 = paciente\n",
    "        elif paciente.unidad_actual == p.dict_unidades[\"ED\"] and paciente.hospital_actual == 2:\n",
    "            paciente_ed_2 = paciente\n",
    "        elif paciente.unidad_actual == p.dict_unidades[\"ED\"] and paciente.hospital_actual == 3:\n",
    "            paciente_ed_3 = paciente\n",
    "        elif paciente.unidad_actual == p.dict_unidades[\"WL\"]:\n",
    "            paciente_wl = paciente\n",
    "        if paciente_ed_1 and paciente_ed_2 and paciente_ed_3 and paciente_wl:\n",
    "            break\n",
    "\n",
    "# 3 | {1: [1, 2, 3]} | {1: [1, 3, 12]}\n",
    "paciente = paciente_wl\n",
    "print(paciente.ti_inicial, \"|\",paciente.camino, \"|\", paciente.espera)\n",
    "print(paciente)\n",
    "\n",
    "paciente.cambiar_unidad(p.dict_hospitales[\"Hospital_1\"], p.dict_unidades[\"GA\"])\n",
    "imprimir_log(paciente.log_eventos, ultimo = True)\n",
    "\n",
    "paciente.cambiar_unidad(paciente.hospital_actual, paciente.unidad_requerida)\n",
    "imprimir_log(paciente.log_eventos, ultimo = True)\n",
    "\n",
    "for unidades in range(len(paciente.camino[paciente.hospital_actual]) - 1): # la ultima la ve el while\n",
    "    for i in range(paciente.espera[paciente.hospital_actual][0]):\n",
    "        paciente.actualizar_tiempo()\n",
    "    # paciente.actualizar_tiempo() # espera 1 cada vez\n",
    "    paciente.cambiar_unidad(paciente.hospital_actual, paciente.unidad_requerida)\n",
    "    imprimir_log(paciente.log_eventos, ultimo = True)\n",
    "\n",
    "while paciente.unidad_requerida != p.dict_unidades[\"END\"]:\n",
    "    paciente.actualizar_tiempo()\n",
    "paciente.cambiar_unidad(paciente.hospital_actual, p.dict_unidades[\"END\"])\n",
    "imprimir_log(paciente.log_eventos, ultimo = True)\n",
    "paciente.costo_social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7008cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h_1)\n",
    "\n",
    "for evento in h_1.ED.pacientes[0].log_eventos:\n",
    "    print(evento)\n",
    "h_1.actualizar_tiempo()\n",
    "paciente = h_1.sacar_paciente(h_1.ED.pacientes[0], p.dict_unidades[\"ED\"])\n",
    "\n",
    "h_1.agregar_paciente(paciente, p.dict_unidades[\"OR\"])\n",
    "\n",
    "print(\"----------------------\")\n",
    "\n",
    "for evento in paciente.log_eventos:\n",
    "    print(evento)\n",
    "\n",
    "h_1.actualizar_tiempo()\n",
    "paciente = h_1.sacar_paciente(paciente, p.dict_unidades[\"OR\"])\n",
    "print(paciente)\n",
    "h_1.agregar_paciente(paciente, p.dict_unidades[\"ICU\"])\n",
    "print(\"----------------------\")\n",
    "for evento in paciente.log_eventos:\n",
    "    print(evento)\n",
    "\n",
    "h_1.actualizar_tiempo()\n",
    "paciente = h_1.sacar_paciente(paciente, p.dict_unidades[\"ICU\"])\n",
    "\n",
    "h_1.agregar_paciente(paciente, p.dict_unidades[\"SDU/WARD\"])\n",
    "print(\"----------------------\")\n",
    "for evento in paciente.log_eventos:\n",
    "    print(evento)\n",
    "\n",
    "print(h_1)\n",
    "\n",
    "h_1.actualizar_tiempo()\n",
    "paciente = h_1.sacar_paciente(paciente, p.dict_unidades[\"SDU/WARD\"])\n",
    "\n",
    "end.agregar_paciente(paciente)\n",
    "print(\"----------------------\")\n",
    "for evento in paciente.log_eventos:\n",
    "    print(evento)\n",
    "\n",
    "pa_2 = h_2.sacar_paciente(h_2.SDU_WARD.pacientes[0], p.dict_unidades[\"SDU/WARD\"])\n",
    "print(pa_2)\n",
    "end.agregar_paciente(pa_2)\n",
    "print(\"----------------------\")\n",
    "\n",
    "\n",
    "for paciente in end.sub_listas[1][4]:\n",
    "    print(paciente.unidad_actual, paciente)\n",
    "\n",
    "print(h_2.ocupacion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7641dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testeo x para ver si funcionan las unidades, si funcionaron\n",
    "# Se instancian a todos los pacientes a partir de los datos de incertidumbre\n",
    "pacientes = {}\n",
    "lista_pacientes = []\n",
    "for hospital in range(0,4): # 0 son llegadas a WL\n",
    "    pacientes[hospital] = {}\n",
    "    for requerimiento in range(1,4):\n",
    "        pacientes[hospital][requerimiento] = {}\n",
    "        for grd in range(1,9):\n",
    "            pacientes[hospital][requerimiento][grd] = []\n",
    "            cantidad_pacientes = len(incertidumbre[hospital][requerimiento][grd])\n",
    "            if cantidad_pacientes != 0:\n",
    "                for i in range(cantidad_pacientes):\n",
    "                    paciente = Paciente(hospital, requerimiento, grd, incertidumbre[hospital][requerimiento][grd][i]) # i es el index de la lista\n",
    "                    pacientes[hospital][requerimiento][grd].append(paciente)\n",
    "                    lista_pacientes.append(paciente)\n",
    "            else:\n",
    "                pacientes[hospital][requerimiento][grd] = []\n",
    "\n",
    "# Se generan tantas listas como pacientes haya\n",
    "def agrupar_pacientes_por_llegada(pacientes):\n",
    "    pacientes_separados_por_llegada = {}\n",
    "    for paciente in pacientes:\n",
    "        dia = paciente.ti_inicial\n",
    "        if dia not in pacientes_separados_por_llegada:\n",
    "            pacientes_separados_por_llegada[dia] = []\n",
    "        pacientes_separados_por_llegada[dia].append(paciente)\n",
    "    return pacientes_separados_por_llegada\n",
    "\n",
    "pacientes_separados_por_llegada = agrupar_pacientes_por_llegada(lista_pacientes)\n",
    "\n",
    "pacientes_prueba = pacientes_separados_por_llegada.get(2)\n",
    "\n",
    "# Prueba unidades\n",
    "or_1 = Or(1)\n",
    "ed_1 = Ed(1)\n",
    "icu_1 = Icu(1)\n",
    "sdu_ward_1 = SduWard(1)\n",
    "ga_1 = Ga(1)\n",
    "termino = Termino([1, 2, 3], [1, 2, 3, 4, 5, 6, 7, 8])\n",
    "print(or_1)\n",
    "for paciente in pacientes_prueba[0:4]:\n",
    "    or_1.agregar_paciente(paciente)\n",
    "print(or_1)\n",
    "\n",
    "# print(pacientes_prueba[0].log_eventos)\n",
    "# pacientes_prueba[0].actualizar_tiempo()\n",
    "# or_1.agregar_paciente(pacientes_prueba[0])\n",
    "# print(pacientes_prueba[0].log_eventos)\n",
    "# pacientes_prueba[0].actualizar_tiempo()\n",
    "# print(or_1.sacar_paciente(pacientes_prueba[0]))\n",
    "# print(or_1.sacar_paciente(pacientes_prueba[0]))\n",
    "# print(or_1.sacar_paciente(pacientes_prueba[0]))\n",
    "# print(or_1.agregar_paciente(pacientes_prueba[0]))\n",
    "# print(or_1.agregar_paciente(pacientes_prueba[0]))\n",
    "# ed_1.agregar_paciente(paciente_sacado)\n",
    "# print(pacientes_prueba[0].log_eventos)\n",
    "# pacientes_prueba[0].actualizar_tiempo()\n",
    "# icu_1.agregar_paciente(pacientes_prueba[0])\n",
    "# print(pacientes_prueba[0].log_eventos)\n",
    "# pacientes_prueba[0].actualizar_tiempo()\n",
    "# ga_1.agregar_paciente(pacientes_prueba[0])\n",
    "# print(pacientes_prueba[0].log_eventos)\n",
    "# pacientes_prueba[0].actualizar_tiempo()\n",
    "# sdu_ward_1.agregar_paciente(pacientes_prueba[0])\n",
    "# print(pacientes_prueba[0].log_eventos)\n",
    "# termino.agregar_paciente(pacientes_prueba[0])\n",
    "# print(pacientes_prueba[0].log_eventos)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88023aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajuste_kde(dato: list, ocurrencias: list, bandwidth: float = 1, pvalue: float = 0.06, plot: bool = True, titulo_plot: str = \"Ajuste KDE\"):    \n",
    "    ###################### Datos a analizar ######################\n",
    "    dato = np.array(dato) # Aca no se divide por 12 ya que es cantidad de llegadas por dia\n",
    "    ocurrencias = np.array(ocurrencias)\n",
    "    raw_data = np.repeat(dato, ocurrencias)\n",
    "    ##############################################################\n",
    "    pvalue_obtenido = 0\n",
    "    while pvalue_obtenido < pvalue:\n",
    "        # Estimador del kernerl density discreto #####################\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth).fit(raw_data[:, None])\n",
    "        # Calculo el valor p de la prueba de chi2\n",
    "        metricas, kde_pdf = calculate_kde_metrics(dato, ocurrencias, kde)\n",
    "        pvalue_obtenido = metricas[\"Chi2\"][\"p-value\"]\n",
    "        # Si el pvalue obtenido es menor al pvalue deseado, disminuyo el ancho de banda\n",
    "        if pvalue_obtenido < pvalue:\n",
    "            # Disminuyo el ancho de banda\n",
    "            bandwidth -= 0.005\n",
    "            # Si el ancho de banda es menor a 0.01, salgo del while\n",
    "            if bandwidth < 0.01:\n",
    "                print(\"No se encontró un ancho de banda adecuado sobre 0.5\")\n",
    "                break\n",
    "        ##############################################################\n",
    "\n",
    "    if plot:\n",
    "        ###################### Plot ##################################\n",
    "        # Histograma de los datos, tantos bins como el valor maximo de los datos\n",
    "        plt.figure(figsize=(10, 3)) # tamaño grafico\n",
    "        plt.bar(dato, ocurrencias / ocurrencias.sum(), alpha=0.6, color='g', edgecolor='black', label='Bar Plot')\n",
    "\n",
    "        # pdf del KDE ajustado a los datos\n",
    "        x_vals = np.linspace(min(raw_data), max(raw_data), 1000)\n",
    "        log_dens = kde.score_samples(x_vals[:, None])\n",
    "        kde_pdf = np.exp(log_dens)\n",
    "        plt.plot(x_vals, kde_pdf, color='black', label=f'KDE (Bandwidth = {round(bandwidth,2)})')\n",
    "        # puntos de las intersecciones\n",
    "        x_vals_puntos = np.linspace(int(min(raw_data)), int(max(raw_data)), int(max(raw_data)) - int(min(raw_data)) + 1)\n",
    "        log_dens_puntos = kde.score_samples(x_vals_puntos[:, None])\n",
    "        kde_pdf_puntos = np.exp(log_dens_puntos)\n",
    "        plt.scatter(x_vals_puntos, kde_pdf_puntos, color='red', label=f'KDE intersecciones')\n",
    "\n",
    "\n",
    "        # Leyendas y nombres\n",
    "        plt.xlabel('LOS')\n",
    "        plt.ylabel('Densidad')\n",
    "        plt.title(titulo_plot)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        ##############################################################\n",
    "    \n",
    "    return kde, kde_pdf, metricas, bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cccae175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 1): 0,\n",
       " (1, 2): 0,\n",
       " (1, 3): 0,\n",
       " (2, 1): 0,\n",
       " (2, 2): 0,\n",
       " (2, 3): 0,\n",
       " (3, 1): 0,\n",
       " (3, 2): 0,\n",
       " (3, 3): 0,\n",
       " (4, 1): 0,\n",
       " (4, 2): 0,\n",
       " (4, 3): 0,\n",
       " (5, 1): 0,\n",
       " (5, 2): 2,\n",
       " (5, 3): 4,\n",
       " (6, 1): 2,\n",
       " (6, 2): 2,\n",
       " (6, 3): 0,\n",
       " (7, 1): 1,\n",
       " (7, 2): 1,\n",
       " (7, 3): 2,\n",
       " (8, 1): 0,\n",
       " (8, 2): 0,\n",
       " (8, 3): 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"WL\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bb9242",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Distintos tipos de bandwith para ir probando\n",
    "dict_bandwith = {\n",
    "    'normal_mean': ((4/(3*len(raw_data)))**(1/5)) * np.std(raw_data),\n",
    "    'normal_mean_iqr': ((4/(3*len(raw_data)))**(1/5)) * (np.percentile(raw_data, 75) - np.percentile(raw_data, 25)),\n",
    "    \"scott\": 1.06 * np.std(raw_data) * (len(raw_data) ** (-1 / 5))\n",
    "}\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53bff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo internet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.stats import norm, lognorm, gamma, poisson, chisquare, kstest, pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "rand_seed = 100\n",
    "\n",
    "def make_data_normal(data_count=100):\n",
    "    np.random.seed(rand_seed)\n",
    "    x = np.random.normal(0, 1, data_count)\n",
    "    dist = lambda z: stats.norm(0, 1).pdf(z)\n",
    "    return x, dist\n",
    "\n",
    "def make_data_binormal(data_count=100):\n",
    "    alpha = 0.3\n",
    "    np.random.seed(rand_seed)\n",
    "    x = np.concatenate([\n",
    "        np.random.normal(-1, 2, int(data_count * alpha)),\n",
    "        np.random.normal(5, 1, int(data_count * (1 - alpha)))\n",
    "    ])\n",
    "    dist = lambda z: alpha * stats.norm(-1, 2).pdf(z) + (1 - alpha) * stats.norm(5, 1).pdf(z)\n",
    "    return x, dist\n",
    "\n",
    "def make_data_exp(data_count=100):\n",
    "    alpha = 0.3\n",
    "    np.random.seed(rand_seed)\n",
    "    x = np.concatenate([\n",
    "        np.random.exponential(1, int(data_count * alpha)),\n",
    "        np.random.exponential(1, int(data_count * (1 - alpha))) + 1\n",
    "    ])\n",
    "    dist = lambda z: alpha * stats.expon(0).pdf(z) + (1 - alpha) * stats.expon(1).pdf(z)\n",
    "    return x, dist\n",
    "\n",
    "def make_data_uniform(data_count=100):\n",
    "    alpha = 0.3\n",
    "    np.random.seed(rand_seed)\n",
    "    x = np.concatenate([\n",
    "        np.random.uniform(-1, 1, int(data_count * alpha)),\n",
    "        np.random.uniform(0, 1, int(data_count * (1 - alpha)))\n",
    "    ])\n",
    "    dist = lambda z: alpha * stats.uniform(-1, 1).pdf(z) + (1 - alpha) * stats.uniform(0, 1).pdf(z)\n",
    "    return x, dist\n",
    "\n",
    "x_norm, dist_norm = make_data_normal()\n",
    "x_binorm, dist_binorm = make_data_binormal()\n",
    "x_exp, dist_exp = make_data_exp()\n",
    "x_uni, dist_uni = make_data_uniform()\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(12, 3))\n",
    "names = ['Normal', 'Bi-normal', 'Exponential', 'Bi-Uniform']\n",
    "for i, d in enumerate([dist_norm, dist_binorm, dist_exp, dist_uni]):\n",
    "    x = np.linspace(-8, 8, 100)\n",
    "    ax[i].fill(x, d(x), color='C0', alpha=0.5)\n",
    "    ax[i].set_ylim(0, 1)\n",
    "    ax[i].set_xlim(-8, 8)\n",
    "    ax[i].set_xlabel('x')\n",
    "    ax[i].set_ylabel('p(x)')\n",
    "    ax[i].set_title(names[i])\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "\n",
    "def kernel(k: str):\n",
    "    \"\"\"Kernel Functions.\n",
    "    Ref: https://en.wikipedia.org/wiki/Kernel_(statistics)\n",
    "\n",
    "    Args:\n",
    "        k (str): Kernel name. Can be one of ['gaussian', 'epanechnikov', 'cosine', 'linear'.]\n",
    "    \"\"\"\n",
    "    \n",
    "    if k not in ['gaussian', 'epanechnikov', 'cosine', 'linear']:\n",
    "        raise ValueError('Unknown kernel.')\n",
    "\n",
    "    def bounded(f):\n",
    "        def _f(x):\n",
    "            return f(x) if np.abs(x) <= 1 else 0\n",
    "        return _f\n",
    "\n",
    "    if k == 'gaussian':\n",
    "        return lambda u: 1 / np.sqrt(2 * np.pi) * np.exp(-1 / 2 * u * u)\n",
    "    elif k == 'epanechnikov':\n",
    "        return bounded(lambda u: (3 / 4 * (1 - u * u)))\n",
    "    elif k =='cosine':\n",
    "        return bounded(lambda u: np.pi / 4 * np.cos(np.pi / 2 * u))\n",
    "    elif k == 'linear':\n",
    "        return bounded(lambda u: 1 - np.abs(u))\n",
    "    \n",
    "def bw_scott(data: np.ndarray):\n",
    "    std_dev = np.std(data, axis=0, ddof=1)\n",
    "    n = len(data)\n",
    "    return 3.49 * std_dev * n ** (-0.333)\n",
    "\n",
    "def bw_silverman(data: np.ndarray):\n",
    "    def _select_sigma(x):\n",
    "        normalizer = 1.349\n",
    "        iqr = (stats.scoreatpercentile(x, 75) - stats.scoreatpercentile(x, 25)) / normalizer\n",
    "        std_dev = np.std(x, axis=0, ddof=1)\n",
    "        return np.minimum(std_dev, iqr) if iqr > 0 else std_dev\n",
    "    sigma = _select_sigma(data)\n",
    "    n = len(data)\n",
    "    return 0.9 * sigma * n ** (-0.2)\n",
    "\n",
    "def bw_mlcv(data: np.ndarray, k):\n",
    "    \"\"\"\n",
    "    Ref: https://rdrr.io/cran/kedd/src/R/MLCV.R\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    x = np.linspace(np.min(data), np.max(data), n)\n",
    "    def mlcv(h):\n",
    "        fj = np.zeros(n)\n",
    "        for j in range(n):\n",
    "            for i in range(n):\n",
    "                if i == j: continue\n",
    "                fj[j] += k((x[j] - data[i]) / h)\n",
    "            fj[j] /= (n - 1) * h\n",
    "        return -np.mean(np.log(fj[fj > 0]))\n",
    "    h = optimize.minimize(mlcv, 1)\n",
    "    if np.abs(h.x[0]) > 10:\n",
    "        return bw_scott(data)\n",
    "    return h.x[0]\n",
    "\n",
    "def kde(data, k=None, h=None, x=None):\n",
    "    \"\"\"Kernel Density Estimation.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): Data.\n",
    "        k (function): Kernel function.\n",
    "        h (float): Bandwidth.\n",
    "        x (np.ndarray, optional): Grid. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Kernel density estimation.\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        x = np.linspace(np.min(data), np.max(data), 1000)\n",
    "    if h is None:\n",
    "        h = bw_silverman(data)\n",
    "    if k is None:\n",
    "        k = kernel('gaussian')\n",
    "    n = len(data)\n",
    "    kde = np.zeros_like(x)\n",
    "    for j in range(len(x)):\n",
    "        for i in range(n):\n",
    "            kde[j] += k((x[j] - data[i]) / h)\n",
    "        kde[j] /= n * h\n",
    "    return kde\n",
    "\n",
    "data = [\n",
    "    ('Normal', make_data_normal),\n",
    "    ('Bimodal (Normal)', make_data_binormal),\n",
    "    ('Bimodal (Exp)', make_data_exp),\n",
    "    ('Bimodal (Uniform)', make_data_uniform)\n",
    "]\n",
    "kernels = [\n",
    "    ('Gaussian', kernel('gaussian')),\n",
    "    ('Epanechnikov', kernel('epanechnikov')),\n",
    "    ('Cosine', kernel('cosine')),\n",
    "    ('Linear', kernel('linear'))\n",
    "]\n",
    "bw_algorithms = [\n",
    "    ('Scott', bw_scott),\n",
    "    ('Silverman', bw_silverman),\n",
    "    ('MLCV', bw_mlcv),\n",
    "]\n",
    "mses = []\n",
    "\n",
    "def run_kde(ax, data, kernel):\n",
    "    x, dist = data[1]()\n",
    "    x_plot = np.linspace(np.min(x) * 1.05, np.max(x) * 1.05, 1000)\n",
    "    ax.grid(True)\n",
    "    ax.fill_between(x_plot, dist(x_plot), fc='silver', alpha=0.5)\n",
    "    ax.plot(x, np.full_like(x, -0.02), '|k', markeredgewidth=1)\n",
    "    ax.hist(x, density=True, alpha=0.2, bins=20, rwidth=0.9)\n",
    "    for bw in bw_algorithms:\n",
    "        if bw[0] == 'MLCV':\n",
    "            h = bw[1](x, kernel[1])\n",
    "        else:\n",
    "            h = bw[1](x)\n",
    "        x_kde = kde(x, kernel[1], h=h, x=x_plot)\n",
    "        mse = np.mean((dist(x_plot) - x_kde) ** 2)\n",
    "        mses.append({\n",
    "            'data': data[0],\n",
    "            'kernel': kernel[0],\n",
    "            'bw_algorithm': bw[0],\n",
    "            'h': round(h, 5),\n",
    "            'mse': round(mse * 1000, 5), # To make differences more noticable\n",
    "        })\n",
    "        ax.plot(x_plot, x_kde, linewidth=1, label='$h_{\\mathrm{' + bw[0] + '}} = ' + str(round(h, 5)) + '$')\n",
    "    ax.legend(loc='best', fontsize='small')\n",
    "    ax.set_title(f'{data[0]}, {kernel[0]}')\n",
    "\n",
    "fig, axs = plt.subplots(len(data), len(kernels), figsize=(16, 12))\n",
    "\n",
    "for i, d in enumerate(data):\n",
    "    for j, k in enumerate(kernels):\n",
    "        run_kde(axs[i, j], d, k)\n",
    "    for bw in bw_algorithms:\n",
    "        avg_h = np.mean([m['h'] for m in mses if m['data'] == d[0] and m['bw_algorithm'] == bw[0]])\n",
    "        avg_mse = np.mean([m['mse'] for m in mses if m['data'] == d[0] and m['bw_algorithm'] == bw[0]])\n",
    "        mses.append({\n",
    "            'data': d[0],\n",
    "            'kernel': '-',\n",
    "            'bw_algorithm': bw[0],\n",
    "            'h': round(avg_h, 5),\n",
    "            'mse': round(avg_mse, 5),\n",
    "        })\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig('eval.pdf')\n",
    "pd.DataFrame(mses).to_csv('eval.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f6466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,4):\n",
    "    for grd in range(1,9):\n",
    "        for unidad in [\"ICU\", \"SDU_WARD\"]:\n",
    "            # ---- 1. Filter your dataset\n",
    "            tl_u = tl[tl[\"UNIDAD\"].isin([\"ICU\", \"OR\", \"SDU_WARD\"])]\n",
    "            v1 = tl_u[(tl_u[\"UNIDAD\"] == unidad) & (tl_u[\"MS_GRD\"] == grd) & (tl_u[\"HOSPITAL\"] == f\"Hospital_{i}\")]\n",
    "            # v1 = tl_u[(tl_u[\"UNIDAD\"] == unidad) & (tl_u[\"MS_GRD\"] == grd)]\n",
    "\n",
    "            # ---- 2. Get LOS value counts\n",
    "            vector = v1[\"LOS\"].value_counts().reset_index().sort_values(by=\"LOS\")\n",
    "            vector.columns = [\"LOS\", \"count\"]\n",
    "\n",
    "            # ---- 3. Build raw data from LOS values and their frequencies\n",
    "            los = np.array(vector[\"LOS\"])\n",
    "            ocurrencias = np.array(vector[\"count\"])\n",
    "            raw_data = np.repeat(los, ocurrencias)\n",
    "\n",
    "\n",
    "            # ---- 4. Definir los bins de 12 horas\n",
    "            bin_width = 12\n",
    "            max_los = np.max(raw_data)\n",
    "            edges = np.arange(0, max_los + bin_width, bin_width)\n",
    "            midpoints = (edges[:-1] + edges[1:]) / 2  # midpoint of (a, b] is (a + b) / 2\n",
    "    \n",
    "\n",
    "            # ---- 5. Meter datos a bins individuales (0 - 12], (12 - 24], ...)\n",
    "            # agrega 0 si no hay datos para ese bin\n",
    "            bin_indices = np.digitize(raw_data, edges, right=True)\n",
    "            hist = np.array([(bin_indices == i).sum() for i in range(1, len(edges))])\n",
    "\n",
    "#--------------------------------Hasta aca esta bien----------------------------------------\n",
    "\n",
    "            # ---- 6. Fit log-normal distribution to the raw data\n",
    "            shape, loc, scale = stats.lognorm.fit(raw_data, floc=0)\n",
    "\n",
    "\n",
    "\n",
    "            # # ---- Optimización\n",
    "            # def chi2_objective(params, hist, edges, total_count):\n",
    "            #     shape, loc, scale = params\n",
    "            #     # Ensure parameters are valid\n",
    "            #     if shape <= 0 or scale <= 0:\n",
    "            #         return np.inf\n",
    "            #     cdf_low = stats.lognorm.cdf(edges[:-1], shape, loc, scale)\n",
    "            #     cdf_high = stats.lognorm.cdf(edges[1:], shape, loc, scale)\n",
    "            #     expected_probs = cdf_high - cdf_low\n",
    "            #     expected_counts = expected_probs * total_count\n",
    "\n",
    "            #     # Mask for bins with enough expected values\n",
    "            #     mask = expected_counts >= 5\n",
    "            #     if not np.any(mask):\n",
    "            #         return np.inf\n",
    "            #     obs = hist[mask]\n",
    "            #     exp = expected_counts[mask]\n",
    "                \n",
    "            #     # Normalize expected to match sum of obs\n",
    "            #     exp *= obs.sum() / exp.sum()\n",
    "\n",
    "            #     chi2 = np.sum((obs - exp)**2 / exp)\n",
    "            #     return chi2\n",
    "            # initial_shape, initial_loc, initial_scale = stats.lognorm.fit(raw_data, floc=0)\n",
    "            # # Minimize the chi-square\n",
    "            # result = minimize(\n",
    "            #     chi2_objective,\n",
    "            #     x0=[initial_shape, initial_loc, initial_scale],\n",
    "            #     args=(hist, edges, len(raw_data)),\n",
    "            #     bounds=[(1e-5, None), (0, None), (1e-5, None)],\n",
    "            #     method='L-BFGS-B'\n",
    "            # )\n",
    "            # # Extract optimized parameters\n",
    "            # opt_shape, opt_loc, opt_scale = result.x\n",
    "            # # print(f\"Optimized shape={opt_shape:.4f}, loc={opt_loc:.4f}, scale={opt_scale:.2f}\")\n",
    "            # shape = opt_shape\n",
    "            # loc = opt_loc\n",
    "            # scale = opt_scale\n",
    "\n",
    "\n",
    "            # # ---- 7. Compute expected counts per bin using log-normal CDF\n",
    "            # cdf_low = stats.lognorm.cdf(edges[:-1], shape, loc, scale)\n",
    "            # cdf_high = stats.lognorm.cdf(edges[1:], shape, loc, scale)\n",
    "            # expected_probs = cdf_high - cdf_low\n",
    "            # # Acumulo todo lo que queda de la cola en el ultimo bin\n",
    "            # # expected_probs[-1] = 1 - (sum(expected_probs) - expected_probs[-1])\n",
    "            # expected_counts = expected_probs * len(raw_data)\n",
    "\n",
    "\n",
    "            # # ---- 9. Chi-square test (only where expected counts ≥ 5)\n",
    "            # mask = expected_counts >= 5\n",
    "            # obs = hist[mask]\n",
    "            # exp = expected_counts[mask]\n",
    "\n",
    "            # # display(obs)\n",
    "            # # display(exp)\n",
    "\n",
    "            # # Normalize expected counts to match the total of observed\n",
    "            # if exp.sum() > 0:\n",
    "            #     exp *= obs.sum() / exp.sum()\n",
    "\n",
    "            # # Chi-square test\n",
    "            # if np.any(mask):\n",
    "            #     chi2, p = stats.chisquare(f_obs=obs, f_exp=exp)\n",
    "            #     if p > 0.05:\n",
    "            #         print(f\"Chi² = {chi2:.2f}, p-value = {p:.10f}, Unidad={unidad}, Hospital={i}, GRD={grd}\")\n",
    "                    \n",
    "            #         # ---- 8. Plot observed vs. expected\n",
    "            #         plt.figure(figsize=(12, 6))\n",
    "            #         plt.bar(midpoints, hist, width=bin_width - 2, alpha=0.6, label='Observed (12h bins)')\n",
    "            #         plt.plot(midpoints, expected_counts, 'r--o', label='Log-normal expected')\n",
    "            #         plt.xlabel('Length of Stay (hours)')\n",
    "            #         plt.ylabel('Frequency')\n",
    "            #         plt.title(f'LOS Histogram vs Log-normal Fit\\nUnidad={unidad}, Hospital={i}, GRD={grd}')\n",
    "            #         plt.grid(True)\n",
    "\n",
    "            #         # Curva continua\n",
    "            #         x_vals = np.linspace(1, max_los, 500)\n",
    "            #         pdf_vals = stats.lognorm.pdf(x_vals, s=shape, loc=loc, scale=scale)\n",
    "            #         pdf_scaled = pdf_vals * len(raw_data) * bin_width\n",
    "            #         plt.plot(x_vals, pdf_scaled, 'g-', label='Log-normal PDF (smoothed)')\n",
    "\n",
    "            #         plt.legend()\n",
    "            #         plt.show()\n",
    "            #         break\n",
    "\n",
    "                    \n",
    "            # else:\n",
    "            #     print(\"Chi-square test skipped: not enough expected counts ≥ 5.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7931e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla para los OR\n",
    "\n",
    "tabla = {\n",
    "    1: [[\"MS_GRD\", \"LOS = 12\", \"LOS = 24\"]],\n",
    "    2: [[\"MS_GRD\", \"LOS = 12\", \"LOS = 24\"]],\n",
    "    3: [[\"MS_GRD\", \"LOS = 12\", \"LOS = 24\"]]\n",
    "}\n",
    "\n",
    "for i in range(1,4):\n",
    "    for grd in range(1,9):\n",
    "        for unidad in [\"OR\"]:\n",
    "            # ---- 1. Filter your dataset\n",
    "            tl_u = tl[tl[\"UNIDAD\"].isin([\"ICU\", \"OR\", \"SDU_WARD\"])]\n",
    "            v1 = tl_u[(tl_u[\"UNIDAD\"] == unidad) & (tl_u[\"MS_GRD\"] == grd) & (tl_u[\"HOSPITAL\"] == f\"Hospital_{i}\")]\n",
    "            # v1 = tl_u[(tl_u[\"UNIDAD\"] == unidad) & (tl_u[\"MS_GRD\"] == grd)]\n",
    "\n",
    "            # ---- 2. Get LOS value counts\n",
    "            vector = v1[\"LOS\"].value_counts().reset_index().sort_values(by=\"LOS\")\n",
    "            vector[\"%\"] = vector[\"count\"] / vector[\"count\"].sum()\n",
    "            vector1 = vector[[\"LOS\", \"%\"]].reset_index()\n",
    "\n",
    "            los_12 = 0\n",
    "            los_24 = 0\n",
    "            for index, row in vector1.iterrows():\n",
    "                if row[\"LOS\"] == 12:\n",
    "                    los_12 = row[\"%\"]\n",
    "                elif row[\"LOS\"] == 24:\n",
    "                    los_24 = row[\"%\"]\n",
    "\n",
    "            tabla[i].append([grd, round(los_12,5), round(los_24,5)])\n",
    "                    \n",
    "            \n",
    "\n",
    "    display(tabla[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ffe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasar a tablas de latex\n",
    "for key, h in tabla.items():\n",
    "\n",
    "    texto = f\"\"\"\n",
    "\\\\begin{{table}}[H]\n",
    "    \\\\centering\n",
    "    \\\\begin{{tabular}}{{ccc}}\n",
    "        \\\\toprule\n",
    "        MS\\_GRD & LOS = 12 & LOS = 24 \\\\\\\\\n",
    "        \\\\midrule\n",
    "        {h[1][0]} & {h[1][1]} & {h[1][2]} \\\\\\\\\n",
    "        {h[2][0]} & {h[2][1]} & {h[2][2]} \\\\\\\\\n",
    "        {h[3][0]} & {h[3][1]} & {h[3][2]} \\\\\\\\\n",
    "        {h[4][0]} & {h[4][1]} & {h[4][2]} \\\\\\\\\n",
    "        {h[5][0]} & {h[5][1]} & {h[5][2]} \\\\\\\\\n",
    "        {h[6][0]} & {h[6][1]} & {h[6][2]} \\\\\\\\\n",
    "        {h[7][0]} & {h[7][1]} & {h[7][2]} \\\\\\\\\n",
    "        {h[8][0]} & {h[8][1]} & {h[8][2]} \\\\\\\\\n",
    "        \\\\bottomrule\n",
    "    \\\\end{{tabular}}\n",
    "    \\\\caption{{Probabilidad LOS en OR para Hospital: {key}}}\n",
    "    \\\\label{{tab:Probabilidad LOS en OR para Hospital: {key}}}\n",
    "\\\\end{{table}}\n",
    "    \"\"\"\n",
    "\n",
    "    print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6592e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segundo intento (quedo pesimo)\n",
    "\n",
    "# for i in range(1,4):\n",
    "# for grd in range(1,9):\n",
    "# for unidad in [\"ICU\", \"SDU_WARD\"]:\n",
    "\n",
    "unidad = \"ICU\"  # Cambiar unidad\n",
    "grd = 1\n",
    "\n",
    "# ---- 1. Filtra los datos para obtener LOS y cantidad de ocurrencias\n",
    "tl_u = tl[tl[\"UNIDAD\"].isin([\"ICU\", \"OR\", \"SDU_WARD\"])]\n",
    "# v1 = tl_u[(tl_u[\"UNIDAD\"] == unidad) & (tl_u[\"MS_GRD\"] == grd) & (tl_u[\"HOSPITAL\"] == f\"Hospital_{i}\")]\n",
    "v1 = tl_u[(tl_u[\"UNIDAD\"] == unidad) & (tl_u[\"MS_GRD\"] == grd)]\n",
    "\n",
    "# ---- 2. Calcular la cantidad de veces que se repite ese LOS\n",
    "vector = v1[\"LOS\"].value_counts().reset_index().sort_values(by=\"LOS\")\n",
    "vector.columns = [\"LOS\", \"count\"]\n",
    "\n",
    "# ---- 3. Pasarlo a formato para histograma\n",
    "los = np.array(vector[\"LOS\"])\n",
    "ocurrencias = np.array(vector[\"count\"])\n",
    "raw_data = np.repeat(los, ocurrencias) # multiplica LOS por cantidad de repeticiones\n",
    "\n",
    "# ---- 4. Definir los bins de 12 horas (para ajustar la curva)\n",
    "bin_width = 12\n",
    "max_los = np.max(raw_data) # Elige el maximo de LOS\n",
    "edges = np.arange(0, max_los + bin_width, bin_width) # Define los bins\n",
    "midpoints = (edges[:-1] + edges[1:]) / 2  # Define puntos medios de los bins\n",
    "\n",
    "# ---- 5. Meter datos a bins individuales (0 - 12], (12 - 24], ...) agrega 0 si no hay datos para ese bin\n",
    "bin_indices = np.digitize(raw_data, edges, right=True)\n",
    "hist = np.array([(bin_indices == i).sum() for i in range(1, len(edges))])\n",
    "bin_edges = edges\n",
    "bin_upper_bounds = bin_edges[1:]\n",
    "\n",
    "# ---- 6. Ajustar distribución a los datos en bins de 12 horas\n",
    "shape, loc, scale = stats.lognorm.fit(raw_data, floc = 0)\n",
    "\n",
    "# # Grafico para la curva suave log_normal\n",
    "# x = np.linspace(min(bin_upper_bounds), max(bin_upper_bounds), 1000)\n",
    "# y = stats.lognorm.pdf(x, shape, loc, scale) * len(raw_data) * bin_width\n",
    "# plt.hist(raw_data, bins=bin_edges, alpha=0.6, color='g', label=\"Histogram\")\n",
    "# plt.plot(x, y, label=\"Fitted Log-normal\", color='r')\n",
    "# plt.xlabel('Value')\n",
    "# plt.ylabel('Density')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# Define interval of interest\n",
    "  # for example\n",
    "N = len(raw_data)\n",
    "maximo = int(raw_data[-1])\n",
    "maximo = int(maximo/12)\n",
    "expected = []\n",
    "for i in range(0, maximo):\n",
    "    a = i * 12\n",
    "    b = (i + 1) * 12\n",
    "    p_interval = stats.lognorm.cdf(b, shape, loc, scale) - stats.lognorm.cdf(a, shape, loc, scale)\n",
    "    expected_occurrences = N * p_interval\n",
    "    expected.append(expected_occurrences)\n",
    "esperado = np.array(expected)\n",
    "observado = hist\n",
    "\n",
    "# Test de chi cuadrado\n",
    "mask = esperado >= 5\n",
    "\n",
    "obs = observado[mask]\n",
    "exp = esperado[mask]\n",
    "\n",
    "exp *= obs.sum() / exp.sum()\n",
    "\n",
    "chi2, p = stats.chisquare(f_obs=obs, f_exp=exp)\n",
    "print(f\"chi2 = {chi2}, p = {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83902231",
   "metadata": {},
   "outputs": [],
   "source": [
    "los = [12, 24, 36, 48, 60, 72]\n",
    "count = [5, 12, 8, 6, 4, 2]\n",
    "\n",
    "def continuous(los, count):\n",
    "    nueva_lista = []\n",
    "    lista_cuartos = []\n",
    "    for i in range(len(los)):\n",
    "        # for j in range(count[i]):\n",
    "        #     nueva_lista.append(los[i])\n",
    "        nueva_lista.append(round((count[i])/4, 2))\n",
    "    for cuarto in nueva_lista:\n",
    "        lista_cuartos.append(cuarto)\n",
    "        lista_cuartos.append(cuarto * 2)\n",
    "        lista_cuartos.append(cuarto)\n",
    "    \n",
    "    uniones = []\n",
    "    for i in range(0, len(lista_cuartos), 3):\n",
    "        if i == 0:\n",
    "            uniones.append(lista_cuartos[i])\n",
    "            uniones.append(lista_cuartos[i + 1])\n",
    "        elif i == len(lista_cuartos) - 3:\n",
    "            uniones.append(lista_cuartos[i] + lista_cuartos[i - 1])\n",
    "            uniones.append(lista_cuartos[i + 1])\n",
    "            uniones.append(lista_cuartos[i + 2])\n",
    "        else:\n",
    "            uniones.append(lista_cuartos[i] + lista_cuartos[i - 1])\n",
    "            uniones.append(lista_cuartos[i + 1])\n",
    "    \n",
    "    count = uniones.copy()\n",
    "\n",
    "    new_los = []\n",
    "    for i in range(len(uniones)):\n",
    "        if i == 0:\n",
    "            new_los.append(6)\n",
    "        elif i == len(uniones) - 1:\n",
    "            ultimo = new_los[-1]\n",
    "            new_los.append(ultimo + 6)\n",
    "        else:\n",
    "            nuevo = new_los[-1] + 6\n",
    "            new_los.append(nuevo)\n",
    "    \n",
    "    return new_los, count\n",
    "\n",
    "uniones, count = continuous(los, count)\n",
    "\n",
    "print(uniones)\n",
    "print(count)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80040f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros para cuando sea parte de una función\n",
    "plot = True\n",
    "bandwidth = 0.82\n",
    "###################### Datos a analizar ######################\n",
    "tl_u = tl[tl[\"UNIDAD\"].isin([\"ICU\", \"OR\", \"SDU_WARD\"])]\n",
    "v1 = tl_u[(tl_u[\"UNIDAD\"] == \"SDU_WARD\") & (tl_u[\"MS_GRD\"] == 1) & (tl_u[\"HOSPITAL\"] == f\"Hospital_{1}\")]\n",
    "vector = v1[\"LOS\"].value_counts().reset_index().sort_values(by=\"LOS\")\n",
    "vector.columns = [\"LOS\", \"count\"]\n",
    "los = np.array(vector[\"LOS\"])/12 \n",
    "ocurrencias = np.array(vector[\"count\"])\n",
    "raw_data = np.repeat(los, ocurrencias)\n",
    "##############################################################\n",
    "\n",
    "# Estimador del kernerl density discreto #####################\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth).fit(raw_data[:, None])\n",
    "##############################################################\n",
    "\n",
    "if plot:\n",
    "    ###################### Plot ##################################\n",
    "    # Histograma de los datos, tantos bins como el valor maximo de los datos\n",
    "    plt.figure(figsize=(10, 3)) # tamaño grafico\n",
    "    plt.hist(raw_data, bins=int(raw_data[-1] - (raw_data[0] - 1)), density=True, alpha=0.6, color='g', edgecolor='black', label='Histogram')\n",
    "\n",
    "    # pdf del KDE ajustado a los datos\n",
    "    x_vals = np.linspace(min(raw_data), max(raw_data), 1000)\n",
    "    log_dens = kde.score_samples(x_vals[:, None])\n",
    "    kde_pdf = np.exp(log_dens)\n",
    "    plt.plot(x_vals, kde_pdf, color='black', label=f'KDE (Bandwidth = {round(bandwidth,2)})')\n",
    "    # puntos de las intersecciones\n",
    "    x_vals_puntos = np.linspace(int(min(raw_data)), int(max(raw_data)), int(max(raw_data)) - int(min(raw_data)) + 1)\n",
    "    log_dens_puntos = kde.score_samples(x_vals_puntos[:, None])\n",
    "    kde_pdf_puntos = np.exp(log_dens_puntos)\n",
    "    plt.scatter(x_vals_puntos, kde_pdf_puntos, color='red', label=f'KDE intersecciones')\n",
    "\n",
    "\n",
    "    # Leyendas y nombres\n",
    "    plt.xlabel('LOS')\n",
    "    plt.ylabel('Densidad')\n",
    "    plt.title('Histograma y KDE discreto de LOS')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    ##############################################################\n",
    "\n",
    "metricas, _ = calculate_kde_metrics(los, ocurrencias, kde)\n",
    "display(pd.DataFrame(metricas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_satisfactory_h(data, empirical_counts, support, a1=1, a2=1, initial_h=0.5, p_threshold=0.065):\n",
    "    p = 0\n",
    "    h = initial_h\n",
    "    while p <= p_threshold:\n",
    "        _, kde = discrete_DT_kde(data, a1=a1, a2=a2, h=h, support=support)\n",
    "        expected_counts = kde * empirical_counts.sum()\n",
    "        chi2, p = chisquare(empirical_counts, expected_counts)\n",
    "        if p > p_threshold:\n",
    "            return h, kde, chi2, p\n",
    "        else:\n",
    "            h -= 0.01\n",
    "        if h < 0.02:\n",
    "            print(\"No satisfactory h found.\")\n",
    "            return None, None, None, None\n",
    "            # return h, kde, chi2, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "# Datos de ejemplo (reemplaza con tus propios datos si es necesario)\n",
    "data = {\n",
    "    \"LOS\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
    "    \"count\": [486, 1086, 685, 392, 190, 105, 56, 52, 18, 18, 10, 3, 3, 1, 1, 1, 2, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "los_samples = np.repeat(df[\"LOS\"], df[\"count\"])  # Expande los datos a una lista de muestras\n",
    "\n",
    "# Implementación de KDE discreto según Hirukawa (2010)\n",
    "def hirukawa_discrete_kde(data, bandwidth=1, min_val=None, max_val=None):\n",
    "    if min_val is None:\n",
    "        min_val = np.min(data)\n",
    "    if max_val is None:\n",
    "        max_val = np.max(data)\n",
    "\n",
    "    values = np.arange(min_val, max_val + 1)  # Soporte discreto\n",
    "    pmf = np.zeros_like(values, dtype=float)  # Inicializa la función de masa de probabilidad\n",
    "\n",
    "    for x in data:\n",
    "        # Calcula los pesos del kernel Gaussiano centrado en x\n",
    "        raw_weights = np.exp(-0.5 * ((values - x) / bandwidth) ** 2)\n",
    "        # Normaliza los pesos del kernel para que sumen 1 en cada iteración\n",
    "        normalized_weights = raw_weights / raw_weights.sum()\n",
    "        pmf += normalized_weights  # Acumula los pesos en la PMF\n",
    "\n",
    "    pmf /= pmf.sum()  # Normaliza la PMF total para que sume 1\n",
    "    return values, pmf\n",
    "\n",
    "# Calcula la PMF empírica a partir de los datos\n",
    "values = np.arange(1, 19)\n",
    "empirical_counts = df.set_index(\"LOS\").reindex(values, fill_value=0)[\"count\"].values\n",
    "empirical_pmf = empirical_counts / empirical_counts.sum()\n",
    "\n",
    "# Búsqueda de ancho de banda que cumpla con p > 0.065\n",
    "bandwidths = np.linspace(0.1, 2, 100)\n",
    "satisfactory_bandwidth = None\n",
    "\n",
    "for bw in bandwidths[::-1]:\n",
    "    _, test_pmf = hirukawa_discrete_kde(los_samples, bandwidth=bw, min_val=1, max_val=18)\n",
    "    expected_counts = test_pmf * empirical_counts.sum()  # Escala la PMF para chi-cuadrado\n",
    "    chi2, p_val = chisquare(f_obs=empirical_counts, f_exp=expected_counts)\n",
    "    if p_val > 0.065:\n",
    "        satisfactory_bandwidth = bw\n",
    "        break  # Detiene la búsqueda al encontrar el primer ancho válido\n",
    "\n",
    "# Si se encuentra un KDE satisfactorio, mostrar el gráfico comparativo\n",
    "if satisfactory_bandwidth is not None:\n",
    "    values_kde, kde_pmf = hirukawa_discrete_kde(los_samples, bandwidth=satisfactory_bandwidth, min_val=1, max_val=18)\n",
    "\n",
    "    # Gráfico de comparación entre PMF empírica y KDE ajustado\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(values - 0.2, empirical_pmf, width=0.4, label='PMF Empírica', alpha=0.7)\n",
    "    plt.bar(values + 0.2, kde_pmf, width=0.4, label=f'KDE Hirukawa (bw={satisfactory_bandwidth:.2f})', alpha=0.7)\n",
    "    plt.title(\"Comparación: KDE Discreto de Hirukawa vs PMF Empírica (p > 0.065)\")\n",
    "    plt.xlabel(\"Longitud de Estancia (días)\")\n",
    "    plt.ylabel(\"Probabilidad\")\n",
    "    plt.xticks(values)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Mostrar resultados del test chi-cuadrado final\n",
    "    chi2_final, p_val_final = chisquare(empirical_counts, kde_pmf * empirical_counts.sum())\n",
    "    print(f\"Mejor ancho de banda (p > 0.065): {satisfactory_bandwidth:.2f}\")\n",
    "    print(f\"Estadístico chi-cuadrado: {chi2_final:.4f}\")\n",
    "    print(f\"p-valor: {p_val_final:.4f}\")\n",
    "else:\n",
    "    print(\"No se encontró un ancho de banda que cumpla con p > 0.065.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a07b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puntos de intersección entre data y kde (en los enteros: 1, 2, 3 ...)\n",
    "x_vals = np.linspace(int(min(los)), int(max(los)), int(max(los)))\n",
    "log_dens = kde.score_samples(x_vals[:, None])\n",
    "kde_pdf = np.exp(log_dens)\n",
    "\n",
    "# Almaceno el los y sus ocurrencias en un diccionario\n",
    "dict_temporal = {}\n",
    "for i in range(len(los)):\n",
    "    dict_temporal[int(los[i])] = ocurrencias[i]\n",
    "\n",
    "# Genero ocurrencias nuevamente pero agregando un cero en los intervalos sin ocurrencias\n",
    "ocurrencias_con_cero = []\n",
    "for i in range(1, int(max(los)) + 1):\n",
    "    ocurrencias_con_cero.append(dict_temporal.get(i, 0))\n",
    "ocurrencias_con_cero = np.array(ocurrencias_con_cero)\n",
    "\n",
    "# Calculo las métricas para el kde (que es el unico que voy a usar)\n",
    "def get_metrics(y_true, y_pred):\n",
    "    prediccion = y_pred * (y_true.sum() / y_pred.sum()) # reescala predicciones para el test\n",
    "    chi2 = chisquare(f_obs=y_true, f_exp=prediccion)\n",
    "    ks_stat = ks_2samp(y_true, y_pred)\n",
    "    cc= pearsonr(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        'Chi2': {\"Value\": round(chi2.statistic, 3), \"p-value\": round(chi2.pvalue, 3)},\n",
    "        'KS': {\"Value\": round(ks_stat.statistic, 3), \"p-value\": round(ks_stat.pvalue, 3)},\n",
    "        'CC': {\"Value\": round(cc.statistic, 3), \"p-value\": round(cc.pvalue, 3)},\n",
    "        'R2': {\"Value\": round(r2, 3), \"p-value\": \"NA\"},\n",
    "        'RMSE': {\"Value\": round(rmse, 3), \"p-value\": \"NA\"},\n",
    "        'MAE': {\"Value\": round(mae, 3), \"p-value\": \"NA\"}\n",
    "    }\n",
    "\n",
    "# Llamo a la función, se utilizan ocurrencias, no probabilidades\n",
    "metrics = get_metrics(ocurrencias_con_cero, kde_pdf*ocurrencias.sum())\n",
    "\n",
    "# Se muestran las metricas\n",
    "display(pd.DataFrame(metrics))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
